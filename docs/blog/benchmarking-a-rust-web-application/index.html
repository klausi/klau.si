<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>Klausi&#x27;s Weblog - Benchmarking a Rust web application</title>

  
  <link rel="alternate"
    type="application/rss+xml"
    title="RSS" href="https://klau.si/rss.xml">
  

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slideout/1.0.1/slideout.min.js"></script>
  
  

  
  <link rel="stylesheet" href="https://klau.si/site.css">
  
  

  
  
</head>

<body>
  <div class="container">

    <div id="mobile-navbar" class="mobile-navbar">
      <div class="mobile-header-logo">
        <a href="https:&#x2F;&#x2F;klau.si" title="Klausi&#x27;s Weblog" rel="home" class="site-logo site-title">
          <img src="https://klau.si/logo.png" alt="Klausi&#x27;s Weblog logo">
        </a>
        <a href="/" class="logo">Klausi&#x27;s Weblog</a>
      </div>
      <div class="mobile-navbar-icon icon-out">
        <span></span>
        <span></span>
        <span></span>
      </div>
    </div>

    <nav id="mobile-menu" class="mobile-menu slideout-menu slideout-menu-left">
      <ul class="mobile-menu-list">
        
        <li class="mobile-menu-item">
          <a href="https:&#x2F;&#x2F;klau.si">
            Home
          </a>
        </li>
        
        <li class="mobile-menu-item">
          <a href="https:&#x2F;&#x2F;klau.si&#x2F;tags&#x2F;speaking">
            Speaking
          </a>
        </li>
        
        <li class="mobile-menu-item">
          <a href="https:&#x2F;&#x2F;klau.si&#x2F;tags">
            Categories
          </a>
        </li>
        
        <li class="mobile-menu-item">
          <a href="https:&#x2F;&#x2F;klau.si&#x2F;rss.xml">
            RSS
          </a>
        </li>
        
      </ul>
    </nav>

    <header id="header">
      <div class="logo">
        <a href="https:&#x2F;&#x2F;klau.si" title="Klausi&#x27;s Weblog" rel="home" class="site-logo site-title">
          <img src="https://klau.si/logo.png" alt="Klausi&#x27;s Weblog logo">
        </a>
        <a href="https:&#x2F;&#x2F;klau.si">Klausi&#x27;s Weblog</a>
      </div>
      <nav class="menu">
        <ul>
          
          <li>
            <a href="https:&#x2F;&#x2F;klau.si">
              Home
            </a>
          </li>
          
          <li>
            <a href="https:&#x2F;&#x2F;klau.si&#x2F;tags&#x2F;speaking">
              Speaking
            </a>
          </li>
          
          <li>
            <a href="https:&#x2F;&#x2F;klau.si&#x2F;tags">
              Categories
            </a>
          </li>
          
          <li>
            <a href="https:&#x2F;&#x2F;klau.si&#x2F;rss.xml">
              RSS
            </a>
          </li>
          
        </ul>
      </nav>
    </header>

    <main>
      <div class="content" id="mobile-panel">
        


<div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">Contents</h2>
    <div class="post-toc-content always-active">
        <nav id="TableOfContents">
            <ul>
                
                <li>
                    <a href="https://klau.si/blog/benchmarking-a-rust-web-application/#manual-performance-testing-with-apachebench" class="toc-link">Manual performance testing with ApacheBench</a>
                    
                </li>
                
                <li>
                    <a href="https://klau.si/blog/benchmarking-a-rust-web-application/#automating-benchmarks-in-code" class="toc-link">Automating benchmarks in code</a>
                    
                </li>
                
                <li>
                    <a href="https://klau.si/blog/benchmarking-a-rust-web-application/#observing-benchmark-regressions" class="toc-link">Observing benchmark regressions</a>
                    
                </li>
                
                <li>
                    <a href="https://klau.si/blog/benchmarking-a-rust-web-application/#conclusion" class="toc-link">Conclusion</a>
                    
                </li>
                
            </ul>
        </nav>
    </div>
</div>


<article class="post">
    
    <header class="post__header">
        <h1 class="post__title">
            <a href="https:&#x2F;&#x2F;klau.si&#x2F;blog&#x2F;benchmarking-a-rust-web-application&#x2F;">Benchmarking a Rust web application</a>
        </h1>
        <div class="post__meta">
            <span class="post__time">2018-08-31</span>
            
        </div>
    </header>

    <div class="post-content">
      <p>Performance testing is an important part when developing a network application - you want to know when you have a regression in request throughput in your service.</p>
<p>I set out out my goal 9 for Rustnish:</p>
<blockquote>
<p>Write benchmark code that compares runtime performance of Rustnish against
<a href="https://varnish-cache.org/">Varnish</a>. Use <code>cargo bench</code> to execute the benchmarks.</p>
</blockquote>
<p>The basic idea of a performance test here is to send many HTTP requests to the web service (the reverse proxy in this case) and measure how fast the responses arrive back. Comparing the results from Rustnish and Varnish should give us an idea if our performance expectations are holding up.</p>
<h2 id="manual-performance-testing-with-apachebench">Manual performance testing with ApacheBench</h2>
<p>A quick way to get performance feedback is to run <code>ab</code> against our reverse proxy. Start the server in release mode (optimized):</p>
<pre style="background-color:#191919;color:#f8f8f2;"><code><span>cargo run --release
</span><span>   Compiling rustnish v0.0.1 (file:///home/klausi/workspace/rustnish)
</span><span>    Finished release [optimized] target(s) in 6.02s
</span><span>     Running `target/release/rustnish`
</span><span>Listening on http://127.0.0.1:9090
</span></code></pre>
<p>As backend service I'm using the default Ubuntu Apache webserver running on port 80. It delivers a static default test page.</p>
<p>Benchmarking by sending 10k requests, 100 in parallel:</p>
<pre style="background-color:#191919;color:#f8f8f2;"><code><span>$ ab -c 100 -n 10000 http://127.0.0.1:9090/
</span><span>This is ApacheBench, Version 2.3 &lt;$Revision: 1807734 $&gt;
</span><span>...
</span><span>Benchmarking 127.0.0.1 (be patient)
</span><span>...
</span><span>Concurrency Level:      100
</span><span>Time taken for tests:   1.011 seconds
</span><span>Complete requests:      10000
</span><span>Failed requests:        0
</span><span>Total transferred:      116200000 bytes
</span><span>HTML transferred:       113210000 bytes
</span><span>Requests per second:    9893.12 [#/sec] (mean)
</span><span>Time per request:       10.108 [ms] (mean)
</span><span>Time per request:       0.101 [ms] (mean, across all concurrent requests)
</span><span>Transfer rate:          112263.78 [Kbytes/sec] received
</span><span>...
</span></code></pre>
<p>That looks quite OK!</p>
<p>Of course it is easy for our reverse proxy to reach this throughput: it does not do anything except passing requests through and adding its own header.</p>
<p>Now we install Varnish on Ubuntu:</p>
<pre style="background-color:#191919;color:#f8f8f2;"><code><span>sudo apt install varnish
</span></code></pre>
<p>We configure it to do the sane thing as Rustnish, just passing all requests through. /etc/varnish/default.vcl:</p>
<pre style="background-color:#191919;color:#f8f8f2;"><code><span>vcl 4.0;
</span><span>
</span><span># Default backend definition. Set this to point to your content server.
</span><span>backend default {
</span><span>    .host = &quot;127.0.0.1&quot;;
</span><span>    .port = &quot;80&quot;;
</span><span>}
</span><span>
</span><span>sub vcl_recv {
</span><span>    return (pass);
</span><span>}
</span></code></pre>
<p>And benchmark it:</p>
<pre style="background-color:#191919;color:#f8f8f2;"><code><span>$ ab -c 100 -n 10000 http://127.0.0.1:6081/
</span><span>This is ApacheBench, Version 2.3 &lt;$Revision: 1807734 $&gt;
</span><span>...
</span><span>Benchmarking 127.0.0.1 (be patient)
</span><span>...
</span><span>Concurrency Level:      100
</span><span>Time taken for tests:   1.182 seconds
</span><span>Complete requests:      10000
</span><span>Failed requests:        0
</span><span>Total transferred:      116553545 bytes
</span><span>HTML transferred:       113210000 bytes
</span><span>Requests per second:    8458.46 [#/sec] (mean)
</span><span>Time per request:       11.822 [ms] (mean)
</span><span>Time per request:       0.118 [ms] (mean, across all concurrent requests)
</span><span>Transfer rate:          96275.68 [Kbytes/sec] received
</span></code></pre>
<p>As you can see Varnish performs slightly worse than Rustnish - which means we are on the right track! Of course Varnish has a much bigger code base with much more complexity compared to our most basic reverse proxy that just passes requests through. This difference is to be expected.</p>
<h2 id="automating-benchmarks-in-code">Automating benchmarks in code</h2>
<p>While manual testing is fine we want to automate multiple benchmark scenarios into a benchmark suite that can be executed quickly in one go. <code>cargo bench</code> can help us with that - <a href="https://doc.rust-lang.org/stable/unstable-book/library-features/test.html">the unstable Rust book describes what you need to do to use it</a>.</p>
<p>The book has some good points of advice, one point that we are going to deliberately ignore:</p>
<blockquote>
<p>Make the code in the iter loop do something simple, to assist in pinpointing performance improvements (or regressions)</p>
</blockquote>
<p>But we want to do a full black box performance test of our service here, so our benchmark will be an HTTP client that sends requests and measures response times. This is not a trivial thing to do with Hyper because there are no example guides of how to send requests in parallel. Here is a helper function I came up with:</p>
<pre data-lang="rust" style="background-color:#191919;color:#f8f8f2;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="font-style:italic;color:#fbdfb5;">fn </span><span style="color:#8cdaff;">bench_requests</span><span>(</span><span style="font-style:italic;color:#fc9354;">b</span><span>: </span><span style="color:#ff5e5e;">&amp;mut </span><span>test::Bencher, </span><span style="font-style:italic;color:#fc9354;">amount</span><span>: </span><span style="font-style:italic;color:#fbdfb5;">u32</span><span>, </span><span style="font-style:italic;color:#fc9354;">concurrency</span><span>: </span><span style="font-style:italic;color:#fbdfb5;">u32</span><span>, </span><span style="font-style:italic;color:#fc9354;">proxy_port</span><span>: </span><span style="font-style:italic;color:#fbdfb5;">u16</span><span>) {
</span><span>    </span><span style="color:#6d6d6d;">// Initialize all the Tokio runtime stuff.
</span><span>    </span><span style="font-style:italic;color:#fbdfb5;">let </span><span style="color:#ff5e5e;">mut</span><span> core </span><span style="color:#ff5e5e;">= </span><span>Core::new().</span><span style="color:#6699cc;">unwrap</span><span>();
</span><span>    </span><span style="font-style:italic;color:#fbdfb5;">let</span><span> handle </span><span style="color:#ff5e5e;">=</span><span> core.</span><span style="color:#6699cc;">handle</span><span>();
</span><span>    </span><span style="font-style:italic;color:#fbdfb5;">let</span><span> client </span><span style="color:#ff5e5e;">= </span><span>hyper::Client::new(</span><span style="color:#ff5e5e;">&amp;</span><span>handle);
</span><span>
</span><span>    </span><span style="color:#6d6d6d;">// Target is localhost with the port of the proxy under test.
</span><span>    </span><span style="font-style:italic;color:#fbdfb5;">let</span><span> url: hyper::Uri </span><span style="color:#ff5e5e;">= </span><span>format!(</span><span style="color:#ffffff;">&quot;</span><span style="color:#fbe3bf;">http://127.0.0.1:</span><span style="color:#fdb082;">{}</span><span style="color:#fbe3bf;">/get</span><span style="color:#ffffff;">&quot;</span><span>, proxy_port)
</span><span>        .</span><span style="color:#6699cc;">parse</span><span>()
</span><span>        .</span><span style="color:#6699cc;">unwrap</span><span>();
</span><span>
</span><span>    </span><span style="color:#6d6d6d;">// This is the benchmark loop that will be executed multiple times and
</span><span>    </span><span style="color:#6d6d6d;">// measured.
</span><span>    b.</span><span style="color:#6699cc;">iter</span><span>(</span><span style="color:#ff5e5e;">move || </span><span>{
</span><span>        </span><span style="color:#6d6d6d;">// Build a list of futures that we will execute all at once in parallel
</span><span>        </span><span style="color:#6d6d6d;">// in the end.
</span><span>        </span><span style="font-style:italic;color:#fbdfb5;">let </span><span style="color:#ff5e5e;">mut</span><span> parallel </span><span style="color:#ff5e5e;">= </span><span style="color:#fbe3bf;">Vec</span><span>::new();
</span><span>        </span><span style="color:#ff5e5e;">for</span><span> _i </span><span style="color:#ff5e5e;">in </span><span style="color:#fdb082;">0</span><span style="color:#ff5e5e;">..</span><span>concurrency {
</span><span>            </span><span style="color:#6d6d6d;">// A future that sends requests sequentially by scheduling itself in
</span><span>            </span><span style="color:#6d6d6d;">// a loop-like way.
</span><span>            </span><span style="font-style:italic;color:#fbdfb5;">let</span><span> requests_til_done </span><span style="color:#ff5e5e;">= </span><span style="color:#6699cc;">loop_fn</span><span>(</span><span style="color:#fdb082;">0</span><span>, |</span><span style="font-style:italic;color:#fc9354;">counter</span><span>| {
</span><span>                client
</span><span>                    .</span><span style="color:#6699cc;">get</span><span>(url.</span><span style="color:#6699cc;">clone</span><span>())
</span><span>                    .</span><span style="color:#6699cc;">and_then</span><span>(|</span><span style="font-style:italic;color:#fc9354;">res</span><span>| {
</span><span>                        assert_eq!(
</span><span>                            res.</span><span style="color:#6699cc;">status</span><span>(),
</span><span>                            hyper::StatusCode::Ok,
</span><span>                            </span><span style="color:#ffffff;">&quot;</span><span style="color:#fbe3bf;">Did not receive a 200 HTTP status code. Make sure Varnish is configured on port 6081 and the backend port is set to 9091 in /etc/varnish/default.vcl. Make sure the backend server is running with `cargo run --example hello_9091` and Rustnish with `cargo run --release --example rustnish_9090`.</span><span style="color:#ffffff;">&quot;</span><span>);
</span><span>                        </span><span style="color:#6d6d6d;">// Read response body until the end.
</span><span>                        res.</span><span style="color:#6699cc;">body</span><span>().</span><span style="color:#6699cc;">for_each</span><span>(|</span><span style="font-style:italic;color:#fc9354;">_chunk</span><span>| </span><span style="color:#fbe3bf;">Ok</span><span>(()))
</span><span>                    })
</span><span>                    </span><span style="color:#6d6d6d;">// Break condition of the future &quot;loop&quot;. The return values
</span><span>                    </span><span style="color:#6d6d6d;">// signal the loop future if it should run another iteration
</span><span>                    </span><span style="color:#6d6d6d;">// or not.
</span><span>                    .</span><span style="color:#6699cc;">and_then</span><span>(</span><span style="color:#ff5e5e;">move |_| </span><span>{
</span><span>                        </span><span style="color:#ff5e5e;">if</span><span> counter </span><span style="color:#ff5e5e;">&lt; </span><span>(amount </span><span style="color:#ff5e5e;">/</span><span> concurrency) {
</span><span>                            </span><span style="color:#fbe3bf;">Ok</span><span>(Loop::Continue(counter </span><span style="color:#ff5e5e;">+ </span><span style="color:#fdb082;">1</span><span>))
</span><span>                        } </span><span style="color:#ff5e5e;">else </span><span>{
</span><span>                            </span><span style="color:#fbe3bf;">Ok</span><span>(Loop::Break(counter))
</span><span>                        }
</span><span>                    })
</span><span>            });
</span><span>            parallel.</span><span style="color:#6699cc;">push</span><span>(requests_til_done);
</span><span>        }
</span><span>
</span><span>        </span><span style="color:#6d6d6d;">// The execution should finish when all futures are done.
</span><span>        </span><span style="font-style:italic;color:#fbdfb5;">let</span><span> work </span><span style="color:#ff5e5e;">= </span><span style="color:#6699cc;">join_all</span><span>(parallel);
</span><span>        </span><span style="color:#6d6d6d;">// Now run it! Up to this point no request has been sent, we just
</span><span>        </span><span style="color:#6d6d6d;">// assembled heavily nested futures so far.
</span><span>        core.</span><span style="color:#6699cc;">run</span><span>(work).</span><span style="color:#6699cc;">unwrap</span><span>();
</span><span>    });
</span><span>}
</span></code></pre>
<p>Now we can define bench scenarios that should be measured, for example:</p>
<pre data-lang="rust" style="background-color:#191919;color:#f8f8f2;" class="language-rust "><code class="language-rust" data-lang="rust"><span>#[</span><span style="color:#e9fdac;">bench</span><span>]
</span><span style="font-style:italic;color:#fbdfb5;">fn </span><span style="color:#8cdaff;">c_100_requests</span><span>(</span><span style="font-style:italic;color:#fc9354;">b</span><span>: </span><span style="color:#ff5e5e;">&amp;mut </span><span>test::Bencher) {
</span><span>    </span><span style="color:#6699cc;">bench_requests</span><span>(b, </span><span style="color:#fdb082;">100</span><span>, </span><span style="color:#fdb082;">1</span><span>, </span><span style="color:#fdb082;">9090</span><span>);
</span><span>}
</span><span>
</span><span>#[</span><span style="color:#e9fdac;">bench</span><span>]
</span><span style="font-style:italic;color:#fbdfb5;">fn </span><span style="color:#8cdaff;">c_100_requests_varnish</span><span>(</span><span style="font-style:italic;color:#fc9354;">b</span><span>: </span><span style="color:#ff5e5e;">&amp;mut </span><span>test::Bencher) {
</span><span>    </span><span style="color:#6699cc;">bench_requests</span><span>(b, </span><span style="color:#fdb082;">100</span><span>, </span><span style="color:#fdb082;">1</span><span>, </span><span style="color:#fdb082;">6081</span><span>);
</span><span>}
</span></code></pre>
<p>The full source code with the scenarios can be found in the <a href="https://github.com/klausi/rustnish/blob/goal-09/benches/rustnish_vs_varnish.rs">goal-09 branch</a>.</p>
<p>Before this benchmark can be executed we need Varnish running on port 6081 (default) and we need to start a dummy backend and our proxy server:</p>
<pre style="background-color:#191919;color:#f8f8f2;"><code><span>cargo run --release --example hello_9091
</span><span>cargo run --release --example rustnish_9090
</span></code></pre>
<p>Executing <code>cargo bench</code> then gives us this:</p>
<pre style="background-color:#191919;color:#f8f8f2;"><code><span>running 12 tests
</span><span>test a_1_request                       ... bench:     364,246 ns/iter (+/- 103,690)
</span><span>test a_1_request_varnish               ... bench:     389,026 ns/iter (+/- 63,051)
</span><span>test b_10_requests                     ... bench:   1,874,980 ns/iter (+/- 377,843)
</span><span>test b_10_requests_varnish             ... bench:   2,152,368 ns/iter (+/- 356,510)
</span><span>test c_100_requests                    ... bench:  17,507,140 ns/iter (+/- 2,847,238)
</span><span>test c_100_requests_varnish            ... bench:  21,896,708 ns/iter (+/- 5,546,318)
</span><span>test d_10_parallel_requests            ... bench:   1,646,869 ns/iter (+/- 228,179)
</span><span>test d_10_parallel_requests_varnish    ... bench:   2,012,392 ns/iter (+/- 426,878)
</span><span>test e_100_parallel_requests           ... bench:   8,508,973 ns/iter (+/- 361,317)
</span><span>test e_100_parallel_requests_varnish   ... bench:   9,574,347 ns/iter (+/- 764,147)
</span><span>test f_1_000_parallel_requests         ... bench:  82,898,926 ns/iter (+/- 1,037,534)
</span><span>test f_1_000_parallel_requests_varnish ... bench:  86,922,588 ns/iter (+/- 1,687,902)
</span></code></pre>
<p>Cool, that shows our proxy always being slightly faster than Varnish.</p>
<h2 id="observing-benchmark-regressions">Observing benchmark regressions</h2>
<p>Now that we have established a performance base line we can change or refactor our code and check what happens to our benchmark numbers. My Rustnish project is built on the Hyper library version 0.11, let's see what happens if I update and rewrite to Hyper 0.12 (code in the <a href="https://github.com/klausi/rustnish/tree/hyper-0.12-upgrade">hyper-0.12-upgrade branch</a>) and run the same benchmark:</p>
<pre style="background-color:#191919;color:#f8f8f2;"><code><span>test a_1_request                       ... bench:     554,467 ns/iter (+/- 75,441)
</span><span>test a_1_request_varnish               ... bench:     495,228 ns/iter (+/- 94,544)
</span><span>test b_10_requests                     ... bench:   3,022,574 ns/iter (+/- 1,797,736)
</span><span>test b_10_requests_varnish             ... bench:   2,755,437 ns/iter (+/- 500,961)
</span><span>test c_100_requests                    ... bench:  27,405,520 ns/iter (+/- 2,611,418)
</span><span>test c_100_requests_varnish            ... bench:  24,964,495 ns/iter (+/- 3,385,641)
</span><span>test d_10_parallel_requests            ... bench:   5,712,737 ns/iter (+/- 11,442,635)
</span><span>test d_10_parallel_requests_varnish    ... bench:   1,684,061 ns/iter (+/- 264,177)
</span><span>test e_100_parallel_requests           ... bench:  25,301,274 ns/iter (+/- 35,737,625)
</span><span>test e_100_parallel_requests_varnish   ... bench:   8,721,555 ns/iter (+/- 897,422)
</span><span>test f_1_000_parallel_requests         ... bench:  69,946,899 ns/iter (+/- 36,979,491)
</span><span>test f_1_000_parallel_requests_varnish ... bench:  76,219,659 ns/iter (+/- 10,381,027)
</span></code></pre>
<p>Ouch, that is quite a heavy performance regression! Some observations:</p>
<ul>
<li>Varnish is now faster in almost all scenarios - which probably means that there is a performance regression in our reverse proxy.</li>
<li>Serial requests seem to get processed slower now. That could indicate a regression in the Hyper example server or in our Hyper client code.</li>
<li>There are huge timing deviations between benchmark iterations when Rustnish is used. Could point to some inefficiency when many requests are handled at the same time.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Automated benchmarks are great when you want to track the performance of your application over time. <code>cargo bench</code> is useful, unfortunately it is only available on Rust Nightly. The biggest challenge when doing a big black box performance test is to isolate the cause once you have determined a performance regression. Why and where is it happening? Is it really the application or the benchmark code? Can I reproduce the behavior with manual performance testing?</p>
<p>The Hyper library does not seem to be a good fit for me when writing a reverse proxy. After finding a <a href="https://klau.si/blog/testing-memory-leaks-in-rust/">memory leak</a>, a <a href="https://klau.si/blog/crashing-a-rust-hyper-server-with-a-denial-of-service-attack/">denial of service weakness</a> and now this performance regression I think it is time to try another framework next.</p>
<p><strong>Update 2018-09-07:</strong> seanmonster has some good insights about multi-threading performance in <a href="https://www.reddit.com/r/rust/comments/9bukvy/blog_post_benchmarking_a_rustlang_web_application/e56484j">their Reddit comments</a>. I was able to get Rustnish benchmark numbers ahead of Varnish again, but only by setting Tokio to be single-threaded. So in my single computer (but 4 CPU core) scenario Hyper is only able to compete with Varnish if we eliminate Tokio multithreading. The question remains: Varnish is multithreaded with 2 threadpools and potentially very many threads, why can it handle that so much better than Tokio?</p>
<p>I also <a href="https://github.com/klausi/rustnish/blob/actix-web-test/src/lib.rs">quickly tested actix-web</a> as a replacement for Hyper, but that delivered even worse benchmark results. I think I'll stick to Hyper for now :-)</p>

    </div>

    
    

    <div class="post-footer">
        
            
                <div class="post-tags">
                    
                        <a href="https://klau.si/tags/rust/">#rust</a>
                    
                        <a href="https://klau.si/tags/rustnish/">#rustnish</a>
                    
                </div>
            
            
                <div class="post-nav">
                    
                        <a class="previous" href="https:&#x2F;&#x2F;klau.si&#x2F;blog&#x2F;crashing-a-rust-hyper-server-with-a-denial-of-service-attack&#x2F;">‹ Crashing a Rust Hyper server with a Denial of Service attack</a>
                    
                    
                        <a class="next" href="https:&#x2F;&#x2F;klau.si&#x2F;blog&#x2F;drupal-security-vulnerability-learnings&#x2F;">Drupal Austria Meetup: Drupal security learnings ›</a>
                    
                    
                    
                </div>
            

        

    </div>

    
    
</article>


      </div>
    </main>

    
    <footer>
      <p><a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License"
            style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work by
        <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Klaus Purer</span> is licensed
        under a <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons
          Attribution-ShareAlike 4.0 International License</a>.
      </p>
    </footer>
    
  </div>

  
  <script type="text/javascript" src="https://klau.si/even.js"></script>
  
</body>

</html>
